{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> Attention Mechanism Enabled Clustering using pre trained word vectors </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/sdin-swt-far-54/miniconda3/envs/taufiq/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/sdin-swt-far-54/miniconda3/envs/taufiq/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/sdin-swt-far-54/miniconda3/envs/taufiq/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/sdin-swt-far-54/miniconda3/envs/taufiq/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/sdin-swt-far-54/miniconda3/envs/taufiq/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/sdin-swt-far-54/miniconda3/envs/taufiq/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/sdin-swt-far-54/miniconda3/envs/taufiq/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/sdin-swt-far-54/miniconda3/envs/taufiq/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/sdin-swt-far-54/miniconda3/envs/taufiq/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/sdin-swt-far-54/miniconda3/envs/taufiq/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/sdin-swt-far-54/miniconda3/envs/taufiq/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/sdin-swt-far-54/miniconda3/envs/taufiq/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS BEGIN\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.utils import resample \n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras import initializers\n",
    "from keras.engine.topology import Layer\n",
    "from keras.layers import Dense, Input\n",
    "from keras.layers import Embedding, GRU, Bidirectional, TimeDistributed\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk import tokenize\n",
    "from sklearn import preprocessing\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import MeanShift\n",
    "from sklearn.cluster import Birch\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from matplotlib import pyplot\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# IMPORTS END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBALS BEGIN\n",
    "maxlen=100\n",
    "max_sentences=15\n",
    "max_words=20000\n",
    "embedding_dim=100\n",
    "reviews=[]\n",
    "labels=[]\n",
    "texts=[]\n",
    "embeddings_index={}\n",
    "# GLOBALS END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class Defining Custom Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(Layer):\n",
    "    def __init__(self, attention_dim):\n",
    "        self.init = initializers.get('normal')\n",
    "        self.supports_masking = True\n",
    "        self.attention_dim = attention_dim\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "        self.W = K.variable(self.init((input_shape[-1], self.attention_dim)))\n",
    "        self.b = K.variable(self.init((self.attention_dim,)))\n",
    "        self.u = K.variable(self.init((self.attention_dim, 1)))\n",
    "        self.trainable_weights = [self.W, self.b, self.u]\n",
    "        super(Attention, self).build(input_shape)\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        # size of x :[batch_size, sel_len, attention_dim]\n",
    "        # size of u :[batch_size, attention_dim]\n",
    "        # uit = tanh(xW+b)\n",
    "        uit = K.tanh(K.bias_add(K.dot(x, self.W), self.b))\n",
    "\n",
    "        ait = K.exp(K.squeeze(K.dot(uit, self.u), -1))\n",
    "\n",
    "        if mask is not None:\n",
    "            # Cast the mask to floatX to avoid float64 upcasting\n",
    "            ait *= K.cast(mask, K.floatx())\n",
    "        ait /= K.cast(K.sum(ait, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "        weighted_input = x * K.expand_dims(ait)\n",
    "        output = K.sum(weighted_input, axis=1)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], input_shape[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Reading and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data1 = pd.read_csv('/mnt/SWTM_WORK/FAR_ML_CSS/FA_Predictions/ML_Library/Logs/CTUA/drugscomTrain_raw.tsv', sep='\\t')\n",
    "input_data2 = pd.read_csv('/mnt/SWTM_WORK/FAR_ML_CSS/FA_Predictions/ML_Library/Logs/CTUA/drugscomTest_raw.tsv', sep='\\t')\n",
    "input_data = pd.concat([input_data1, input_data2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>drugName</th>\n",
       "      <th>condition</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>usefulCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>206461</td>\n",
       "      <td>Valsartan</td>\n",
       "      <td>Left Ventricular Dysfunction</td>\n",
       "      <td>\"It has no side effect, I take it in combinati...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>May 20, 2012</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95260</td>\n",
       "      <td>Guanfacine</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>\"My son is halfway through his fourth week of ...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>April 27, 2010</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92703</td>\n",
       "      <td>Lybrel</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"I used to take another oral contraceptive, wh...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>December 14, 2009</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>138000</td>\n",
       "      <td>Ortho Evra</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"This is my first time using any form of birth...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>November 3, 2015</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35696</td>\n",
       "      <td>Buprenorphine / naloxone</td>\n",
       "      <td>Opiate Dependence</td>\n",
       "      <td>\"Suboxone has completely turned my life around...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>November 27, 2016</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215058</th>\n",
       "      <td>159999</td>\n",
       "      <td>Tamoxifen</td>\n",
       "      <td>Breast Cancer, Prevention</td>\n",
       "      <td>\"I have taken Tamoxifen for 5 years. Side effe...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>September 13, 2014</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215059</th>\n",
       "      <td>140714</td>\n",
       "      <td>Escitalopram</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>\"I&amp;#039;ve been taking Lexapro (escitaploprgra...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215060</th>\n",
       "      <td>130945</td>\n",
       "      <td>Levonorgestrel</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"I&amp;#039;m married, 34 years old and I have no ...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>November 15, 2010</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215061</th>\n",
       "      <td>47656</td>\n",
       "      <td>Tapentadol</td>\n",
       "      <td>Pain</td>\n",
       "      <td>\"I was prescribed Nucynta for severe neck/shou...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>November 28, 2011</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215062</th>\n",
       "      <td>113712</td>\n",
       "      <td>Arthrotec</td>\n",
       "      <td>Sciatica</td>\n",
       "      <td>\"It works!!!\"</td>\n",
       "      <td>9.0</td>\n",
       "      <td>September 13, 2009</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>215063 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                  drugName                     condition  \\\n",
       "0           206461                 Valsartan  Left Ventricular Dysfunction   \n",
       "1            95260                Guanfacine                          ADHD   \n",
       "2            92703                    Lybrel                 Birth Control   \n",
       "3           138000                Ortho Evra                 Birth Control   \n",
       "4            35696  Buprenorphine / naloxone             Opiate Dependence   \n",
       "...            ...                       ...                           ...   \n",
       "215058      159999                 Tamoxifen     Breast Cancer, Prevention   \n",
       "215059      140714              Escitalopram                       Anxiety   \n",
       "215060      130945            Levonorgestrel                 Birth Control   \n",
       "215061       47656                Tapentadol                          Pain   \n",
       "215062      113712                 Arthrotec                      Sciatica   \n",
       "\n",
       "                                                   review  rating  \\\n",
       "0       \"It has no side effect, I take it in combinati...     9.0   \n",
       "1       \"My son is halfway through his fourth week of ...     8.0   \n",
       "2       \"I used to take another oral contraceptive, wh...     5.0   \n",
       "3       \"This is my first time using any form of birth...     8.0   \n",
       "4       \"Suboxone has completely turned my life around...     9.0   \n",
       "...                                                   ...     ...   \n",
       "215058  \"I have taken Tamoxifen for 5 years. Side effe...    10.0   \n",
       "215059  \"I&#039;ve been taking Lexapro (escitaploprgra...     9.0   \n",
       "215060  \"I&#039;m married, 34 years old and I have no ...     8.0   \n",
       "215061  \"I was prescribed Nucynta for severe neck/shou...     1.0   \n",
       "215062                                      \"It works!!!\"     9.0   \n",
       "\n",
       "                      date  usefulCount  \n",
       "0             May 20, 2012           27  \n",
       "1           April 27, 2010          192  \n",
       "2        December 14, 2009           17  \n",
       "3         November 3, 2015           10  \n",
       "4        November 27, 2016           37  \n",
       "...                    ...          ...  \n",
       "215058  September 13, 2014           43  \n",
       "215059     October 8, 2016           11  \n",
       "215060   November 15, 2010            7  \n",
       "215061   November 28, 2011           20  \n",
       "215062  September 13, 2009           46  \n",
       "\n",
       "[215063 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(215063, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting count of conditions with reviews greater than equal to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(input_data.groupby('condition').count()['review']>9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for z in x:\n",
    "    if z==True:\n",
    "        count+=1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting count of drugName with reviews greater than equal to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(input_data.groupby('drugName').count()['review']>9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for z in x:\n",
    "    if z==True:\n",
    "        count+=1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep condition which have greater than equal to 10 instances\n",
    "and have max 20 sample of each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_count_per_column(df, column, low=10, high=20):\n",
    "    in_limits_df =  df.groupby(column).filter(lambda x: high>=len(x)>=low)\n",
    "    gt_limit_columns = list(df.groupby(column).filter(lambda x: len(x)>high)[column].unique())\n",
    "    for column_val in gt_limit_columns:\n",
    "        in_limits_df = pd.concat([in_limits_df,resample(df[df[column]==column_val]\n",
    "                                                      ,replace=False,n_samples=20,random_state=100)])\n",
    "    in_limits_df = in_limits_df.reset_index(drop=True)\n",
    "    return in_limits_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = limit_count_per_column(input_data, 'condition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8920, 7)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>drugName</th>\n",
       "      <th>condition</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>usefulCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34093</td>\n",
       "      <td>Zoledronic acid</td>\n",
       "      <td>Osteolytic Bone Metastases of Solid Tumors</td>\n",
       "      <td>\"I dreaded the side-effects and had NONE.  I h...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>January 25, 2012</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>97654</td>\n",
       "      <td>Methimazole</td>\n",
       "      <td>Hyperthyroidism</td>\n",
       "      <td>\"My 6yr old daughter and I have been dealing w...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>July 11, 2016</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>184954</td>\n",
       "      <td>Trolamine salicylate</td>\n",
       "      <td>Bursitis</td>\n",
       "      <td>\"Did help relieve some of the pain temporarily...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>April 19, 2009</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>196987</td>\n",
       "      <td>Paroxetine</td>\n",
       "      <td>Trichotillomania</td>\n",
       "      <td>\"I have OCD, anxiety, and ADHD. I also pick my...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>April 26, 2016</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35476</td>\n",
       "      <td>Phenol</td>\n",
       "      <td>Sore Throat</td>\n",
       "      <td>\"I will personally attest to this,,,\\r\\n33 yea...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>November 5, 2016</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8915</th>\n",
       "      <td>22696</td>\n",
       "      <td>Midodrine</td>\n",
       "      <td>Postural Orthostatic Tachycardia Syndrome</td>\n",
       "      <td>\"Didn&amp;#039;t seem to lower my heart rate very ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>October 1, 2010</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8916</th>\n",
       "      <td>46963</td>\n",
       "      <td>Fludrocortisone</td>\n",
       "      <td>Postural Orthostatic Tachycardia Syndrome</td>\n",
       "      <td>\"I have taken this medicine along with Toprol-...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>August 10, 2010</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8917</th>\n",
       "      <td>41794</td>\n",
       "      <td>Clonidine</td>\n",
       "      <td>Postural Orthostatic Tachycardia Syndrome</td>\n",
       "      <td>\"Very useful for helping to level out the surg...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>May 18, 2013</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8918</th>\n",
       "      <td>163400</td>\n",
       "      <td>Methylphenidate</td>\n",
       "      <td>Postural Orthostatic Tachycardia Syndrome</td>\n",
       "      <td>\"Two months ago, I was unable to work or to dr...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>January 16, 2017</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8919</th>\n",
       "      <td>22687</td>\n",
       "      <td>Midodrine</td>\n",
       "      <td>Postural Orthostatic Tachycardia Syndrome</td>\n",
       "      <td>\"I have been diagnosed with Dysautonomia &amp;amp;...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>October 3, 2015</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8920 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0              drugName  \\\n",
       "0          34093       Zoledronic acid   \n",
       "1          97654           Methimazole   \n",
       "2         184954  Trolamine salicylate   \n",
       "3         196987            Paroxetine   \n",
       "4          35476                Phenol   \n",
       "...          ...                   ...   \n",
       "8915       22696             Midodrine   \n",
       "8916       46963       Fludrocortisone   \n",
       "8917       41794             Clonidine   \n",
       "8918      163400       Methylphenidate   \n",
       "8919       22687             Midodrine   \n",
       "\n",
       "                                       condition  \\\n",
       "0     Osteolytic Bone Metastases of Solid Tumors   \n",
       "1                                Hyperthyroidism   \n",
       "2                                       Bursitis   \n",
       "3                               Trichotillomania   \n",
       "4                                    Sore Throat   \n",
       "...                                          ...   \n",
       "8915   Postural Orthostatic Tachycardia Syndrome   \n",
       "8916   Postural Orthostatic Tachycardia Syndrome   \n",
       "8917   Postural Orthostatic Tachycardia Syndrome   \n",
       "8918   Postural Orthostatic Tachycardia Syndrome   \n",
       "8919   Postural Orthostatic Tachycardia Syndrome   \n",
       "\n",
       "                                                 review  rating  \\\n",
       "0     \"I dreaded the side-effects and had NONE.  I h...    10.0   \n",
       "1     \"My 6yr old daughter and I have been dealing w...     4.0   \n",
       "2     \"Did help relieve some of the pain temporarily...     7.0   \n",
       "3     \"I have OCD, anxiety, and ADHD. I also pick my...    10.0   \n",
       "4     \"I will personally attest to this,,,\\r\\n33 yea...     6.0   \n",
       "...                                                 ...     ...   \n",
       "8915  \"Didn&#039;t seem to lower my heart rate very ...     3.0   \n",
       "8916  \"I have taken this medicine along with Toprol-...    10.0   \n",
       "8917  \"Very useful for helping to level out the surg...     9.0   \n",
       "8918  \"Two months ago, I was unable to work or to dr...     8.0   \n",
       "8919  \"I have been diagnosed with Dysautonomia &amp;...     8.0   \n",
       "\n",
       "                  date  usefulCount  \n",
       "0     January 25, 2012           31  \n",
       "1        July 11, 2016            3  \n",
       "2       April 19, 2009           25  \n",
       "3       April 26, 2016           15  \n",
       "4     November 5, 2016            7  \n",
       "...                ...          ...  \n",
       "8915   October 1, 2010           34  \n",
       "8916   August 10, 2010           14  \n",
       "8917      May 18, 2013           23  \n",
       "8918  January 16, 2017            5  \n",
       "8919   October 3, 2015           12  \n",
       "\n",
       "[8920 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster Train split using Stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = list(input_data['condition'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_and_cluster_data(df, y, stratify_column='condition', cluster_ratio=2/5):    \n",
    "    x_train, x_cluster, y_train, y_cluster = train_test_split(df, y, stratify = df[stratify_column], \n",
    "                                                              test_size = cluster_ratio, random_state=42)\n",
    "    x_train = x_train.reset_index(drop=True)\n",
    "    x_cluster = x_cluster.reset_index(drop=True)\n",
    "    return x_train, x_cluster, y_train, y_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_cluster, y_train, y_cluster = get_train_and_cluster_data(input_data, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5352, 7), (3568, 7))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_cluster.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning and pre processing, using review as input and condition as output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(y_cluster))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(string):\n",
    "    string = re.sub(r\"\\\\\",\"\",string)\n",
    "    string = re.sub(r\"\\'\",\"\",string)\n",
    "    string = re.sub(r\"\\\"\",\"\",string)\n",
    "    return string.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(x_train.review.shape[0]):\n",
    "    text = x_train.review[idx][1:-1]\n",
    "    text = clean_str(text)\n",
    "    texts.append(text)\n",
    "    sentences = tokenize.sent_tokenize(text)\n",
    "    reviews.append(sentences)\n",
    "    labels.append(x_train.condition[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = max_words)\n",
    "tokenizer.fit_on_texts(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.zeros((len(texts), max_sentences, maxlen), dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sentences in enumerate(reviews):\n",
    "    for j, sent in enumerate(sentences):\n",
    "        if j < max_sentences:\n",
    "            wordTokens = text_to_word_sequence(sent)\n",
    "            k=0\n",
    "            for _, word in enumerate(wordTokens):\n",
    "                if k < maxlen and tokenizer.word_index[word] < max_words:\n",
    "                    train_data[i, j, k] = tokenizer.word_index[word]\n",
    "                    k=k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 13279 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Total %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(labels)\n",
    "labels = le.transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([345,  77, 425, ..., 305, 310, 459])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique conditions: 480\n"
     ]
    }
   ],
   "source": [
    "print('unique conditions:', len(set(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of reviews (data) tensor: (5352, 15, 100)\n",
      "Shape of condition (label) tensor: (5352,)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of reviews (data) tensor:', train_data.shape)\n",
    "print('Shape of condition (label) tensor:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(train_data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "train_data = train_data[indices]\n",
    "labels = labels[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using pre available glove embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(os.path.join('/mnt/SWTM_WORK/FAR_ML_CSS/FA_Predictions/ML_Library/Logs/CTUA/', 'glove.6B.100d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word]=coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 400000 word vectors. in pre available glove embeddings\n"
     ]
    }
   ],
   "source": [
    "print('Total %s word vectors. in pre available glove embeddings' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.random.random((len(word_index)+1, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeroes\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sdin-swt-far-54/miniconda3/envs/taufiq/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = Embedding(len(word_index)+1, embedding_dim, weights=[embedding_matrix],\n",
    "                           input_length=maxlen, trainable=True,mask_zero=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention training and final clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_data\n",
    "y_train = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sdin-swt-far-54/miniconda3/envs/taufiq/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/sdin-swt-far-54/miniconda3/envs/taufiq/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/sdin-swt-far-54/miniconda3/envs/taufiq/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/sdin-swt-far-54/miniconda3/envs/taufiq/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/sdin-swt-far-54/miniconda3/envs/taufiq/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2974: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "sentence_input = Input(shape=(maxlen,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sentence_input)\n",
    "lstm_word = Bidirectional(GRU(100, return_sequences=True))(embedded_sequences)\n",
    "attn_word = Attention(100)(lstm_word)\n",
    "sentenceEncoder = Model(sentence_input, attn_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_input = Input(shape=(max_sentences, maxlen), dtype='int32')\n",
    "review_encoder = TimeDistributed(sentenceEncoder)(review_input)\n",
    "lstm_sentence = Bidirectional(GRU(100, return_sequences=True))(review_encoder)\n",
    "attn_sentence = Attention(100)(lstm_sentence)\n",
    "preds = Dense(y_train.shape[1], activation='softmax')(attn_sentence)\n",
    "model = Model(review_input, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sdin-swt-far-54/miniconda3/envs/taufiq/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model fitting - HAN\n",
      "Epoch 1/30\n",
      "5352/5352 [==============================] - 10s 2ms/step - loss: 6.1778 - acc: 0.0017\n",
      "Epoch 2/30\n",
      "5352/5352 [==============================] - 8s 1ms/step - loss: 6.1309 - acc: 0.0058\n",
      "Epoch 3/30\n",
      "5352/5352 [==============================] - 8s 1ms/step - loss: 5.6323 - acc: 0.0377\n",
      "Epoch 4/30\n",
      "5352/5352 [==============================] - 8s 1ms/step - loss: 4.7493 - acc: 0.1286\n",
      "Epoch 5/30\n",
      "5352/5352 [==============================] - 8s 1ms/step - loss: 4.0120 - acc: 0.2552\n",
      "Epoch 6/30\n",
      "5352/5352 [==============================] - 8s 1ms/step - loss: 3.4041 - acc: 0.3602\n",
      "Epoch 7/30\n",
      "5352/5352 [==============================] - 8s 1ms/step - loss: 2.8957 - acc: 0.4559\n",
      "Epoch 8/30\n",
      "5352/5352 [==============================] - 8s 1ms/step - loss: 2.4638 - acc: 0.5387\n",
      "Epoch 9/30\n",
      "5352/5352 [==============================] - 8s 1ms/step - loss: 2.0974 - acc: 0.6087\n",
      "Epoch 10/30\n",
      "5352/5352 [==============================] - 8s 1ms/step - loss: 1.7767 - acc: 0.6809\n",
      "Epoch 11/30\n",
      "5352/5352 [==============================] - 8s 1ms/step - loss: 1.5218 - acc: 0.7379\n",
      "Epoch 12/30\n",
      "5352/5352 [==============================] - 8s 1ms/step - loss: 1.2902 - acc: 0.7814\n",
      "Epoch 13/30\n",
      "5352/5352 [==============================] - 8s 2ms/step - loss: 1.0679 - acc: 0.8309\n",
      "Epoch 14/30\n",
      "5352/5352 [==============================] - 8s 2ms/step - loss: 0.8831 - acc: 0.8700\n",
      "Epoch 15/30\n",
      "5352/5352 [==============================] - 8s 1ms/step - loss: 0.7300 - acc: 0.9036\n",
      "Epoch 16/30\n",
      "5352/5352 [==============================] - 8s 1ms/step - loss: 0.6063 - acc: 0.9273\n",
      "Epoch 17/30\n",
      "5352/5352 [==============================] - 8s 1ms/step - loss: 0.5272 - acc: 0.9406\n",
      "Epoch 18/30\n",
      "5352/5352 [==============================] - 8s 2ms/step - loss: 0.4469 - acc: 0.9550\n",
      "Epoch 19/30\n",
      "5352/5352 [==============================] - 8s 2ms/step - loss: 0.3759 - acc: 0.9647\n",
      "Epoch 20/30\n",
      "5352/5352 [==============================] - 8s 1ms/step - loss: 0.3123 - acc: 0.9722\n",
      "Epoch 21/30\n",
      "5352/5352 [==============================] - 8s 1ms/step - loss: 0.2601 - acc: 0.9766\n",
      "Epoch 22/30\n",
      "5352/5352 [==============================] - 8s 1ms/step - loss: 0.2230 - acc: 0.9798\n",
      "Epoch 23/30\n",
      "5352/5352 [==============================] - 8s 1ms/step - loss: 0.1975 - acc: 0.9819\n",
      "Epoch 24/30\n",
      "5352/5352 [==============================] - 8s 2ms/step - loss: 0.1763 - acc: 0.9839\n",
      "Epoch 25/30\n",
      "5352/5352 [==============================] - 8s 1ms/step - loss: 0.1546 - acc: 0.9854\n",
      "Epoch 26/30\n",
      "5352/5352 [==============================] - 8s 1ms/step - loss: 0.1379 - acc: 0.9865\n",
      "Epoch 27/30\n",
      "5352/5352 [==============================] - 8s 1ms/step - loss: 0.1217 - acc: 0.9882\n",
      "Epoch 28/30\n",
      "5352/5352 [==============================] - 8s 1ms/step - loss: 0.1075 - acc: 0.9901\n",
      "Epoch 29/30\n",
      "5352/5352 [==============================] - 8s 1ms/step - loss: 0.0961 - acc: 0.9907\n",
      "Epoch 30/30\n",
      "5352/5352 [==============================] - 8s 1ms/step - loss: 0.0872 - acc: 0.9922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6648131b50>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"model fitting - HAN\")\n",
    "model.fit(x_train, y_train, epochs= 30, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vec = Model(inputs=review_input,outputs=attn_sentence)\n",
    "model_vec.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = []\n",
    "labels = []\n",
    "texts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(x_cluster.review.shape[0]):\n",
    "    text = x_cluster.review[idx][1:-1]\n",
    "    text = clean_str(text)\n",
    "    texts.append(text)\n",
    "    sentences = tokenize.sent_tokenize(text)\n",
    "    reviews.append(sentences)\n",
    "    labels.append(x_cluster.condition[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = max_words)\n",
    "tokenizer.fit_on_texts(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data = np.zeros((len(texts), max_sentences, maxlen), dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sentences in enumerate(reviews):\n",
    "    for j, sent in enumerate(sentences):\n",
    "        if j < max_sentences:\n",
    "            wordTokens = text_to_word_sequence(sent)\n",
    "            k=0\n",
    "            for _, word in enumerate(wordTokens):\n",
    "                if k < maxlen and tokenizer.word_index[word] < max_words:\n",
    "                    cluster_data[i, j, k] = tokenizer.word_index[word]\n",
    "                    k=k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 11287 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Total %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(labels)\n",
    "labels = le.transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(cluster_data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "cluster_data = cluster_data[indices]\n",
    "labels = labels[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_clustering_vec = model_vec.predict(cluster_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.23342404, -0.18449429, -0.8643042 , -0.31120402, -0.37703496,\n",
       "        0.5581716 , -0.54561603, -0.29393193,  0.15981005, -0.7304628 ,\n",
       "        0.12156442, -0.61072564, -0.17806911,  0.44535375,  0.6431799 ,\n",
       "       -0.8680742 ,  0.26582   , -0.8774233 ,  0.22941095, -0.01846606,\n",
       "       -0.8293949 ,  0.18963313,  0.41653138,  0.01494122, -0.6707307 ,\n",
       "       -0.17027363,  0.6141716 ,  0.86708   ,  0.23090892,  0.5306968 ,\n",
       "       -0.16989005, -0.56456625,  0.5147432 ,  0.02613753, -0.56826925,\n",
       "       -0.05519332,  0.58718854,  0.42939764,  0.28491935, -0.29785746,\n",
       "       -0.06379184, -0.10757115, -0.03291053, -0.31827727,  0.31264722,\n",
       "       -0.19858557, -0.49942166, -0.47481036,  0.45119536, -0.36400783,\n",
       "        0.19320211,  0.27089986, -0.8743253 , -0.7256801 ,  0.42568645,\n",
       "       -0.67707694,  0.07636423, -0.62174296,  0.01825169, -0.03533089,\n",
       "       -0.01956833, -0.9260142 ,  0.70857334,  0.44360995,  0.9359336 ,\n",
       "       -0.15143842, -0.5746393 , -0.0697813 , -0.29139006,  0.36350077,\n",
       "        0.7232189 ,  0.3745285 ,  0.16158462, -0.41894808,  0.00454168,\n",
       "        0.41523618,  0.48225442,  0.25303864, -0.25233978,  0.65564656,\n",
       "       -0.16365471, -0.16089016, -0.5548978 ,  0.19480795, -0.11842993,\n",
       "       -0.03471646,  0.30551302, -0.10538962,  0.15684886,  0.6937878 ,\n",
       "        0.61760676,  0.11662178, -0.07267842, -0.5470622 ,  0.8477502 ,\n",
       "        0.107204  , -0.06826978, -0.33083048,  0.5192626 , -0.77259636,\n",
       "       -0.08793942, -0.01405653,  0.00130021, -0.21032616, -0.00549837,\n",
       "       -0.15913287,  0.10539789, -0.18649219, -0.26070192,  0.27395105,\n",
       "        0.22938028, -0.19573334, -0.37102956, -0.24225353,  0.2611059 ,\n",
       "        0.30501172, -0.28557348, -0.05951923,  0.23915416, -0.19072755,\n",
       "        0.05732772,  0.33736506,  0.14125854,  0.32025278, -0.26118967,\n",
       "       -0.16750364,  0.07234414,  0.32085466, -0.1301956 , -0.3282883 ,\n",
       "        0.19094019, -0.19067696, -0.22306871, -0.16148396,  0.03774695,\n",
       "       -0.23026386, -0.2542153 ,  0.1346046 , -0.06155232,  0.13311914,\n",
       "       -0.18922468, -0.1060417 ,  0.20157225, -0.02114939, -0.29045796,\n",
       "        0.36715478, -0.01036265, -0.15584183,  0.25190917,  0.36014462,\n",
       "       -0.10795017, -0.18236384, -0.13871498,  0.02286361,  0.35960695,\n",
       "       -0.11619204,  0.3446341 , -0.14088693, -0.11097343, -0.23809664,\n",
       "       -0.2781282 , -0.10610656,  0.3466974 , -0.00097084,  0.1257632 ,\n",
       "       -0.21909557,  0.13461755,  0.29192927,  0.1868734 ,  0.14367676,\n",
       "       -0.15004122,  0.08286986, -0.10069691,  0.30716538, -0.30066815,\n",
       "       -0.31651372,  0.22011553,  0.10360385, -0.00762409, -0.08505317,\n",
       "        0.01613883,  0.19342203, -0.06988379,  0.31144005,  0.03450796,\n",
       "       -0.15156096,  0.05745332, -0.15701088,  0.04966847, -0.14917283,\n",
       "        0.177264  ,  0.2629882 ,  0.2270058 ,  0.1991282 , -0.26528412,\n",
       "       -0.09466559,  0.14579028, -0.3090839 ,  0.0049026 ,  0.18240032],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_clustering_vec[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre Clustering Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "pca = PCA(n_components=2)\n",
    "reduced = pca.fit_transform(x_clustering_vec[:100])\n",
    "\n",
    "t = reduced.transpose()\n",
    "\n",
    "plt.scatter(t[0], t[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means(data, n_clusters=480, max_iter=1000):\n",
    "    model = KMeans(n_clusters=n_clusters, max_iter=max_iter).fit(data)\n",
    "    return model\n",
    "def agglomerative_fn(data, n_clusters=480):\n",
    "    model = AgglomerativeClustering(n_clusters = n_clusters).fit(data)\n",
    "    return model\n",
    "def dbscan_fn(data, eps=0.45, min_samples=4):\n",
    "    model = DBSCAN(eps=eps, min_samples=min_samples).fit(data)\n",
    "    return model\n",
    "def mean_shift_fn(data, bandwidth=0.85):\n",
    "    model = MeanShift(bandwidth=bandwidth).fit(data)\n",
    "    return model\n",
    "def birch_fn(data, n_clusters=480):\n",
    "    model = Birch(n_clusters=n_clusters).fit(data)\n",
    "    return model\n",
    "def affinity_propagation_fn(data, damping=0.6, max_iter=1000):\n",
    "    model = AffinityPropagation(damping=damping, max_iter=max_iter).fit(data)\n",
    "    return model\n",
    "def mini_batch_kmeans_fn(data, n_clusters=480, max_iter=1000):\n",
    "    model = MiniBatchKMeans(n_clusters=n_clusters, max_iter=max_iter, batch_size=20).fit(data)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(clustering_model, data, labels):\n",
    "    \n",
    "    model = clustering_model(data)\n",
    "\n",
    "    print('homo\\tcompl\\tv-meas\\tARI\\tAMI\\tsilhouette')\n",
    "    print(50 * '-')\n",
    "    \n",
    "    print('%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f'\n",
    "          %(metrics.homogeneity_score(labels, model.labels_),\n",
    "            metrics.completeness_score(labels, model.labels_),\n",
    "            metrics.v_measure_score(labels, model.labels_),\n",
    "            metrics.adjusted_rand_score(labels, model.labels_),\n",
    "            metrics.adjusted_mutual_info_score(labels,  model.labels_),\n",
    "            metrics.silhouette_score(data, model.labels_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "homo\tcompl\tv-meas\tARI\tAMI\tsilhouette\n",
      "--------------------------------------------------\n",
      "0.658\t0.681\t0.669\t0.020\t0.048\t0.051\n"
     ]
    }
   ],
   "source": [
    "build_model(k_means, x_clustering_vec, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "homo\tcompl\tv-meas\tARI\tAMI\tsilhouette\n",
      "--------------------------------------------------\n",
      "0.677\t0.686\t0.681\t0.022\t0.050\t0.057\n"
     ]
    }
   ],
   "source": [
    "build_model(agglomerative_fn, x_clustering_vec, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "homo\tcompl\tv-meas\tARI\tAMI\tsilhouette\n",
      "--------------------------------------------------\n",
      "0.001\t0.613\t0.002\t-0.000\t-0.000\t-0.124\n"
     ]
    }
   ],
   "source": [
    "build_model(dbscan_fn, x_clustering_vec, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "homo\tcompl\tv-meas\tARI\tAMI\tsilhouette\n",
      "--------------------------------------------------\n",
      "0.999\t0.759\t0.863\t0.029\t0.034\t0.103\n"
     ]
    }
   ],
   "source": [
    "build_model(mean_shift_fn, x_clustering_vec, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "homo\tcompl\tv-meas\tARI\tAMI\tsilhouette\n",
      "--------------------------------------------------\n",
      "0.678\t0.686\t0.682\t0.022\t0.049\t0.053\n"
     ]
    }
   ],
   "source": [
    "build_model(birch_fn, x_clustering_vec, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "homo\tcompl\tv-meas\tARI\tAMI\tsilhouette\n",
      "--------------------------------------------------\n",
      "0.517\t0.628\t0.568\t0.010\t0.033\t0.008\n"
     ]
    }
   ],
   "source": [
    "build_model(affinity_propagation_fn, x_clustering_vec, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "homo\tcompl\tv-meas\tARI\tAMI\tsilhouette\n",
      "--------------------------------------------------\n",
      "0.534\t0.637\t0.581\t0.008\t0.035\t-0.046\n"
     ]
    }
   ],
   "source": [
    "build_model(mini_batch_kmeans_fn, x_clustering_vec, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
